extends ../layouts/base

block variables
  - pageLang = ""
  - pageTitle = "Home"
  - pageDescription = "Page-specific description"
  - pageKeywords = "Page-specific keywords"
  - pageUrl = ""


block body-content
  // $Page header
  header.page-header.js-header
    .page-header__inner
      .page-header__logo
        h1 Tutorial
        | &nbsp;
        span Differentiable Optimization
      nav.page-header__nav.js-nav
        ul
          li
            a.page-header__nav-link.js-anchor.js-link.is-active(href='#home') Home
          li
            a.page-header__nav-link.js-anchor.js-link(href='#portfolio') Tutorial
          li
            a.page-header__nav-link.js-anchor.js-link(href='#team') Team
          li
            a.page-header__nav-link.js-anchor.js-link(href='#contact') Contact


  // $Promo section
  section#home.promo.js-jumbo
    h1.promo__title 
      span IJCAI 2022 Tutorial;
    h2.promo__title
      |
      span Differentiable Optimization: Integrating Structural Information into Training Pipeline
      span July 25th 14:00-17:30 T29 @ Lehar 1

    a.promo__go-next.js-anchor(href='#portfolio') Scroll down


  // $Portfolio section
  section#portfolio.portfolio.js-portfolio
    .portfolio__inner
      h2.portfolio__title Abstract
      p.portfolio__descr Structural information and domain knowledge are two necessary components of training a good machine learning model to maximize the performance in the targeted application. This tutorial summarizes how to use optimization as a differentiable building block to incorporate the non-trivial operational information in applications into machine learning models.

      h2.portfolio__title Tutorial Description
      p.portfolio__descr 
        | Machine learning models have achieved significant success in many industrial applications and social challenges, including natural language processing, computer vision, time series analysis, and recommendation systems. To adapt to different applications, incorporating structural information and domain knowledge in applications into machine learning models is an important element of the training process. But it often relies on fine-tuning and feature-engineering without a systematic approach to adapt to various applications. On the other hand, operational research is an application-driven approach, where optimization problems are formulated based on the knowledge and constraints of targeted applications to derive actionable solutions. Optimization formulations can capture structural information and domain knowledge in applications, but the non-differentiability and the complex operational processes in optimization make it hard to integrate into machine learning models.
      
        <br> <br> This tutorial starts from the foundation of differentiable optimization to discuss how to convert optimization into differentiable building blocks to use in larger architectures. The direct benefit of differentiable optimization is to integrate structural information and domain knowledge in optimization formulations into machine learning models. The first part of the tutorial covers a variety of applications using optimization as differentiable units in machine learning models to properly handle operational tasks in reinforcement learning, control, optimal transport, and geometry. Experiments demonstrate that differentiable optimization can model operational processes more efficiently than neural networks. The second part of the tutorial focuses on integrating various industrial and social challenges as differentiable optimization layers into the training pipeline. This integration of machine learning models and application-driven optimization leads to end-to-end learning, decision-focused learning, that trains models to directly optimize the performance in targeted applications. Lastly, the tutorial concludes with a series of applications of differentiable optimization and its computational limitations with various open directions left to the audiences.



  // $Team section
  section#team.team
    .team__inner
      h2.team__title About us
      .team__member
        img(src='static/images/kai.png', alt='Kai Wang')
        .team__member-info
          h3.team__member-name Kai Wang
          span.team__member-role Harvard University
          p.team__member-descr
            | I am a Ph.D. candidate studying Computer Science at Harvard University working with Professor Milind Tambe. My research focuses on using artificial intelligence to resolve various social challenges, including wildlife conservation and healthcare challenges. I formulate these social challenges as multi-agent systems and learn the unknown information from data using machine learning. I apply and generalize a new learning algorithm, decision-focused learning, to integrate the domain knowledge from social challenges into machine learning pipelines. 
        ul.team__member-soc
          li
            a.team__member-icon.tw(href='https://twitter.com/kaiwang_gua') Follow me on twitter
          li
            a.team__member-icon.gplus(href='https://scholar.google.com/citations?user=gGSsQmsAAAAJ&hl=en') My Google+
          li
            a.team__member-icon.db(href='https://guaguakai.github.io/') Personal website
      .team__member
        img(src='static/images/andrew.png', alt='Andrew Perrault')
        .team__member-info
          h3.team__member-name Andrew Perrault
          span.team__member-role The Ohio State University
          p.team__member-descr
            | I am an assistant professor in the Department of Computer Science and Engineering at The Ohio State University. My research focuses on multi-agent interactions that arise in combating societal challenges, especially in the areas of conservation and public health. These interactions often involve challenges of uncertainty in the environment and the utility functions of the agents, necessitating approaches that handle scarce data. To achieve this end, I combine methodologies from game theory and multi-agent systems with machine learning, robust planning and optimization techniques.
        ul.team__member-soc
          li
            a.team__member-icon.tw(href='https://twitter.com/PerraultAndrew') Follow me on twitter
          li
            a.team__member-icon.gplus(href='https://scholar.google.com/citations?user=2eWscBQAAAAJ&hl=en&oi=ao') My Google+
          li
            a.team__member-icon.db(href='https://aperrault.github.io/') Personal website
      .team__member
        img(src='static/images/brandon.png', alt='Brandon Amos')
        .team__member-info
          h3.team__member-name Brandon Amos
          span.team__member-role Facebook AI (FAIR)
          p.team__member-descr
            | I am a research scientist at Facebook AI (FAIR) in NYC and study foundational topics in machine learning and optimization, recently involving reinforcement learning, control, optimal transport, and geometry. My research is on learning systems that understand and interact with our world and focuses on integrating structural information and domain knowledge into these systems to represent non-trivial reasoning operations. A key theme of my work in this space involves the use of optimization as a differentiable building block in larger architectures that are end-to-end learned. 
        ul.team__member-soc
          li
            a.team__member-icon.tw(href='https://twitter.com/brandondamos') Follow me on twitter
          li
            a.team__member-icon.gplus(href='https://scholar.google.com/citations?user=d8gdZR4AAAAJ') My Google+
          li
            a.team__member-icon.db(href='http://bamos.github.io/') Personal website


  // $Contact section
  section#contact.contact
    .contact__inner
      h2.contact__title Contact us
      p.contact__descr Kai Wang &nbsp | &nbsp 
        a.contact__card-item.email kaiwang@g.harvard.edu


  // $Page footer
  footer.page-footer
    .page-footer__inner
      span.page-footer__copyright &copy; Copyright 2013 Bak-One | One Page Flat Template
      a.page-footer__gotop.js-anchor(href='#home') Go to top
